nohup: 忽略输入
Set max num of threads to 4
Preprocess the data
Corpus(
  num of sentences: 16091
  num of words: 54303
  num of tags: 32
  num of chars: 7477
)

Load the dataset
  size of trainset: 16091
  size of devset: 803
  size of testset: 1910

Create Neural Network
  vocdim: 54303
  chrdim: 7477
  embdim: 100
  char_embdim: 200
  hiddim: 300
  outdim: 32
  lossfn: cross_entropy

LSTM_CHAR(
  (embed): Embedding(54303, 100)
  (clstm): CharLSTM(
    (embed): Embedding(7477, 100)
    (lstm): LSTM(100, 100, batch_first=True, bidirectional=True)
  )
  (wlstm): LSTM(300, 150, batch_first=True, bidirectional=True)
  (out): Linear(in_features=300, out_features=32, bias=True)
  (crf): CRF()
  (drop): Dropout(p=0.5)
)

Use Adam optimizer to train the network
  epochs: 100
  batch_size: 25
  interval: 10
  eta: 0.001

Epoch: 1 / 100:
train: Loss: 6.0159 Accuracy: 404207 / 437991 = 92.29%
dev:   Loss: 5.8174 Accuracy: 18785 / 20454 = 91.84%
0:02:54.963226s elapsed

Epoch: 2 / 100:
train: Loss: 4.2264 Accuracy: 413907 / 437991 = 94.50%
dev:   Loss: 4.6217 Accuracy: 19113 / 20454 = 93.44%
0:03:08.493575s elapsed

Epoch: 3 / 100:
train: Loss: 3.4380 Accuracy: 418360 / 437991 = 95.52%
dev:   Loss: 4.1501 Accuracy: 19247 / 20454 = 94.10%
0:03:00.498824s elapsed

Epoch: 4 / 100:
train: Loss: 2.8388 Accuracy: 421815 / 437991 = 96.31%
dev:   Loss: 3.7944 Accuracy: 19375 / 20454 = 94.72%
0:03:11.638997s elapsed

Epoch: 5 / 100:
train: Loss: 2.4683 Accuracy: 423723 / 437991 = 96.74%
dev:   Loss: 3.7452 Accuracy: 19399 / 20454 = 94.84%
0:03:03.348535s elapsed

Epoch: 6 / 100:
train: Loss: 2.2038 Accuracy: 425236 / 437991 = 97.09%
dev:   Loss: 3.6163 Accuracy: 19451 / 20454 = 95.10%
0:03:08.104677s elapsed

Epoch: 7 / 100:
train: Loss: 1.9624 Accuracy: 426681 / 437991 = 97.42%
dev:   Loss: 3.7285 Accuracy: 19414 / 20454 = 94.92%
0:03:04.298653s elapsed

Epoch: 8 / 100:
train: Loss: 1.7540 Accuracy: 428060 / 437991 = 97.73%
dev:   Loss: 3.7496 Accuracy: 19450 / 20454 = 95.09%
0:02:59.746413s elapsed

Epoch: 9 / 100:
train: Loss: 1.5812 Accuracy: 428941 / 437991 = 97.93%
dev:   Loss: 3.6554 Accuracy: 19466 / 20454 = 95.17%
0:03:01.097070s elapsed

Epoch: 10 / 100:
train: Loss: 1.4200 Accuracy: 429927 / 437991 = 98.16%
dev:   Loss: 3.7548 Accuracy: 19488 / 20454 = 95.28%
0:03:02.542220s elapsed

Epoch: 11 / 100:
train: Loss: 1.3176 Accuracy: 430475 / 437991 = 98.28%
dev:   Loss: 3.7939 Accuracy: 19458 / 20454 = 95.13%
0:03:05.811744s elapsed

Epoch: 12 / 100:
train: Loss: 1.1876 Accuracy: 431381 / 437991 = 98.49%
dev:   Loss: 3.6938 Accuracy: 19514 / 20454 = 95.40%
0:03:18.163498s elapsed

Epoch: 13 / 100:
train: Loss: 1.0853 Accuracy: 431895 / 437991 = 98.61%
dev:   Loss: 3.8657 Accuracy: 19485 / 20454 = 95.26%
0:03:04.997429s elapsed

Epoch: 14 / 100:
train: Loss: 0.9944 Accuracy: 432434 / 437991 = 98.73%
dev:   Loss: 3.8086 Accuracy: 19488 / 20454 = 95.28%
0:03:16.560564s elapsed

Epoch: 15 / 100:
train: Loss: 0.9226 Accuracy: 432886 / 437991 = 98.83%
dev:   Loss: 4.0138 Accuracy: 19480 / 20454 = 95.24%
0:03:08.550970s elapsed

Epoch: 16 / 100:
train: Loss: 0.8250 Accuracy: 433512 / 437991 = 98.98%
dev:   Loss: 3.9297 Accuracy: 19477 / 20454 = 95.22%
0:03:03.844646s elapsed

Epoch: 17 / 100:
train: Loss: 0.7873 Accuracy: 433595 / 437991 = 99.00%
dev:   Loss: 4.0971 Accuracy: 19470 / 20454 = 95.19%
0:03:05.805988s elapsed

Epoch: 18 / 100:
train: Loss: 0.7347 Accuracy: 433951 / 437991 = 99.08%
dev:   Loss: 4.1127 Accuracy: 19498 / 20454 = 95.33%
0:03:55.948559s elapsed

Epoch: 19 / 100:
train: Loss: 0.6461 Accuracy: 434528 / 437991 = 99.21%
dev:   Loss: 4.0955 Accuracy: 19519 / 20454 = 95.43%
0:04:12.689095s elapsed

Epoch: 20 / 100:
train: Loss: 0.6088 Accuracy: 434733 / 437991 = 99.26%
dev:   Loss: 4.2143 Accuracy: 19493 / 20454 = 95.30%
0:04:11.366854s elapsed

Epoch: 21 / 100:
train: Loss: 0.5634 Accuracy: 434919 / 437991 = 99.30%
dev:   Loss: 4.2689 Accuracy: 19510 / 20454 = 95.38%
0:04:12.221256s elapsed

Epoch: 22 / 100:
train: Loss: 0.5196 Accuracy: 435224 / 437991 = 99.37%
dev:   Loss: 4.3136 Accuracy: 19520 / 20454 = 95.43%
0:04:11.416923s elapsed

Epoch: 23 / 100:
train: Loss: 0.4855 Accuracy: 435436 / 437991 = 99.42%
dev:   Loss: 4.4300 Accuracy: 19504 / 20454 = 95.36%
0:04:10.756589s elapsed

Epoch: 24 / 100:
train: Loss: 0.4616 Accuracy: 435570 / 437991 = 99.45%
dev:   Loss: 4.5093 Accuracy: 19500 / 20454 = 95.34%
0:04:10.899406s elapsed

Epoch: 25 / 100:
train: Loss: 0.4308 Accuracy: 435710 / 437991 = 99.48%
dev:   Loss: 4.5077 Accuracy: 19498 / 20454 = 95.33%
0:04:10.441385s elapsed

Epoch: 26 / 100:
train: Loss: 0.4026 Accuracy: 435932 / 437991 = 99.53%
dev:   Loss: 4.6480 Accuracy: 19482 / 20454 = 95.25%
0:04:12.641829s elapsed

Epoch: 27 / 100:
train: Loss: 0.3614 Accuracy: 436180 / 437991 = 99.59%
dev:   Loss: 4.7069 Accuracy: 19480 / 20454 = 95.24%
0:04:05.228172s elapsed

Epoch: 28 / 100:
train: Loss: 0.3424 Accuracy: 436221 / 437991 = 99.60%
dev:   Loss: 4.7808 Accuracy: 19472 / 20454 = 95.20%
0:03:56.739209s elapsed

Epoch: 29 / 100:
train: Loss: 0.3098 Accuracy: 436372 / 437991 = 99.63%
dev:   Loss: 4.8145 Accuracy: 19487 / 20454 = 95.27%
0:03:20.120265s elapsed

Epoch: 30 / 100:
train: Loss: 0.2848 Accuracy: 436567 / 437991 = 99.67%
dev:   Loss: 5.0519 Accuracy: 19476 / 20454 = 95.22%
0:03:13.464510s elapsed

Epoch: 31 / 100:
train: Loss: 0.2718 Accuracy: 436669 / 437991 = 99.70%
dev:   Loss: 4.9662 Accuracy: 19457 / 20454 = 95.13%
0:03:09.710564s elapsed

Epoch: 32 / 100:
train: Loss: 0.2650 Accuracy: 436674 / 437991 = 99.70%
dev:   Loss: 4.9930 Accuracy: 19465 / 20454 = 95.16%
0:03:10.636780s elapsed

Epoch: 33 / 100:
train: Loss: 0.2472 Accuracy: 436748 / 437991 = 99.72%
dev:   Loss: 5.1886 Accuracy: 19470 / 20454 = 95.19%
0:03:13.718515s elapsed

max accuracy of dev is 95.43% at epoch 22
mean time of each epoch is 0:03:27.771725s

test:  Loss: 4.1809 Accuracy: 47954 / 50319 = 95.30%
1:54:19.819685s elapsed

