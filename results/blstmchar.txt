Set max num of threads to 4
Preprocess the data
Corpus(
  num of sentences: 16091
  num of words: 54303
  num of tags: 32
  num of chars: 7477
)

Load the dataset
  size of trainset: 16091
  size of devset: 803
  size of testset: 1910

Create Neural Network
  vocdim: 54303
  chrdim: 7477
  embdim: 100
  char_hiddim: 200
  hiddim: 300
  outdim: 32

LSTM_CHAR(
  (embed): Embedding(54303, 100)
  (clstm): CharLSTM(
    (embed): Embedding(7477, 100)
    (lstm): LSTM(100, 100, batch_first=True, bidirectional=True)
  )
  (wlstm): LSTM(300, 150, batch_first=True, bidirectional=True)
  (out): Linear(in_features=300, out_features=32, bias=True)
  (lossfn): CrossEntropyLoss()
  (drop): Dropout(p=0.5)
)

Use Adam optimizer to train the network
  epochs: 100
  batch_size: 50
  interval: 10
  eta: 0.001

Epoch: 1 / 100:
train: Loss: 0.2350 Accuracy: 404156 / 437991 = 92.27%
dev:   Loss: 0.2521 Accuracy: 18722 / 20454 = 91.53%
0:02:42.146759s elapsed

Epoch: 2 / 100:
train: Loss: 0.1613 Accuracy: 413962 / 437991 = 94.51%
dev:   Loss: 0.1944 Accuracy: 19111 / 20454 = 93.43%
0:02:42.207842s elapsed

Epoch: 3 / 100:
train: Loss: 0.1300 Accuracy: 418624 / 437991 = 95.58%
dev:   Loss: 0.1742 Accuracy: 19290 / 20454 = 94.31%
0:02:40.736753s elapsed

Epoch: 4 / 100:
train: Loss: 0.1109 Accuracy: 421538 / 437991 = 96.24%
dev:   Loss: 0.1703 Accuracy: 19341 / 20454 = 94.56%
0:02:46.418402s elapsed

Epoch: 5 / 100:
train: Loss: 0.0981 Accuracy: 423376 / 437991 = 96.66%
dev:   Loss: 0.1663 Accuracy: 19402 / 20454 = 94.86%
0:02:44.658685s elapsed

Epoch: 6 / 100:
train: Loss: 0.0861 Accuracy: 425298 / 437991 = 97.10%
dev:   Loss: 0.1615 Accuracy: 19434 / 20454 = 95.01%
0:02:49.999409s elapsed

Epoch: 7 / 100:
train: Loss: 0.0780 Accuracy: 426421 / 437991 = 97.36%
dev:   Loss: 0.1667 Accuracy: 19436 / 20454 = 95.02%
0:02:42.769860s elapsed

Epoch: 8 / 100:
train: Loss: 0.0723 Accuracy: 427237 / 437991 = 97.54%
dev:   Loss: 0.1655 Accuracy: 19446 / 20454 = 95.07%
0:02:52.357001s elapsed

Epoch: 9 / 100:
train: Loss: 0.0650 Accuracy: 428350 / 437991 = 97.80%
dev:   Loss: 0.1697 Accuracy: 19477 / 20454 = 95.22%
0:02:47.684638s elapsed

Epoch: 10 / 100:
train: Loss: 0.0596 Accuracy: 429194 / 437991 = 97.99%
dev:   Loss: 0.1657 Accuracy: 19474 / 20454 = 95.21%
0:02:47.517725s elapsed

Epoch: 11 / 100:
train: Loss: 0.0559 Accuracy: 429864 / 437991 = 98.14%
dev:   Loss: 0.1662 Accuracy: 19479 / 20454 = 95.23%
0:02:49.713149s elapsed

Epoch: 12 / 100:
train: Loss: 0.0509 Accuracy: 430573 / 437991 = 98.31%
dev:   Loss: 0.1663 Accuracy: 19526 / 20454 = 95.46%
0:02:49.046044s elapsed

Epoch: 13 / 100:
train: Loss: 0.0459 Accuracy: 431336 / 437991 = 98.48%
dev:   Loss: 0.1657 Accuracy: 19529 / 20454 = 95.48%
0:02:49.598136s elapsed

Epoch: 14 / 100:
train: Loss: 0.0425 Accuracy: 431822 / 437991 = 98.59%
dev:   Loss: 0.1709 Accuracy: 19521 / 20454 = 95.44%
0:02:50.485632s elapsed

Epoch: 15 / 100:
train: Loss: 0.0395 Accuracy: 432273 / 437991 = 98.69%
dev:   Loss: 0.1804 Accuracy: 19498 / 20454 = 95.33%
0:02:47.125660s elapsed

Epoch: 16 / 100:
train: Loss: 0.0370 Accuracy: 432578 / 437991 = 98.76%
dev:   Loss: 0.1811 Accuracy: 19520 / 20454 = 95.43%
0:02:48.633447s elapsed

Epoch: 17 / 100:
train: Loss: 0.0328 Accuracy: 433321 / 437991 = 98.93%
dev:   Loss: 0.1813 Accuracy: 19536 / 20454 = 95.51%
0:02:50.579017s elapsed

Epoch: 18 / 100:
train: Loss: 0.0313 Accuracy: 433560 / 437991 = 98.99%
dev:   Loss: 0.1828 Accuracy: 19514 / 20454 = 95.40%
0:02:44.706460s elapsed

Epoch: 19 / 100:
train: Loss: 0.0287 Accuracy: 433879 / 437991 = 99.06%
dev:   Loss: 0.1879 Accuracy: 19521 / 20454 = 95.44%
0:02:47.754274s elapsed

Epoch: 20 / 100:
train: Loss: 0.0266 Accuracy: 434222 / 437991 = 99.14%
dev:   Loss: 0.1914 Accuracy: 19483 / 20454 = 95.25%
0:02:44.653009s elapsed

Epoch: 21 / 100:
train: Loss: 0.0245 Accuracy: 434548 / 437991 = 99.21%
dev:   Loss: 0.1929 Accuracy: 19501 / 20454 = 95.34%
0:02:46.051919s elapsed

Epoch: 22 / 100:
train: Loss: 0.0222 Accuracy: 434883 / 437991 = 99.29%
dev:   Loss: 0.1931 Accuracy: 19518 / 20454 = 95.42%
0:02:40.478553s elapsed

Epoch: 23 / 100:
train: Loss: 0.0205 Accuracy: 435213 / 437991 = 99.37%
dev:   Loss: 0.1955 Accuracy: 19523 / 20454 = 95.45%
0:02:49.133792s elapsed

Epoch: 24 / 100:
train: Loss: 0.0190 Accuracy: 435343 / 437991 = 99.40%
dev:   Loss: 0.2000 Accuracy: 19484 / 20454 = 95.26%
0:02:47.890979s elapsed

Epoch: 25 / 100:
train: Loss: 0.0181 Accuracy: 435534 / 437991 = 99.44%
dev:   Loss: 0.2055 Accuracy: 19461 / 20454 = 95.15%
0:02:48.091554s elapsed

Epoch: 26 / 100:
train: Loss: 0.0160 Accuracy: 435807 / 437991 = 99.50%
dev:   Loss: 0.2119 Accuracy: 19503 / 20454 = 95.35%
0:02:42.163126s elapsed

Epoch: 27 / 100:
train: Loss: 0.0148 Accuracy: 436000 / 437991 = 99.55%
dev:   Loss: 0.2165 Accuracy: 19503 / 20454 = 95.35%
0:02:50.889830s elapsed

Epoch: 28 / 100:
train: Loss: 0.0140 Accuracy: 436128 / 437991 = 99.57%
dev:   Loss: 0.2147 Accuracy: 19482 / 20454 = 95.25%
0:02:48.806546s elapsed

max accuracy of dev is 95.51% at epoch 17
mean time of each epoch is 0:02:46.867793s

test:  Loss: 0.1469 Accuracy: 48029 / 50319 = 95.45%
1:17:56.077773s elapsed

