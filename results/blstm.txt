Set max num of threads to 4
Preprocess the data
Corpus(
  num of sentences: 16091
  num of words: 54303
  num of tags: 32
  num of chars: 7477
)

Load the dataset
  size of trainset: 16091
  size of devset: 803
  size of testset: 1910

Create Neural Network
  vocdim: 54303
  embdim: 100
  hiddim: 300
  outdim: 32

LSTM(
  (embed): Embedding(54303, 100)
  (lstm): LSTM(100, 150, batch_first=True, bidirectional=True)
  (out): Linear(in_features=300, out_features=32, bias=True)
  (drop): Dropout(p=0.5)
  (lossfn): CrossEntropyLoss()
)

Use Adam optimizer to train the network
  epochs: 100
  batch_size: 25
  interval: 10
  eta: 0.001

Epoch: 1 / 100:
train: Loss: 0.2153 Accuracy: 405696 / 437991 = 92.63%
dev:   Loss: 0.2768 Accuracy: 18769 / 20454 = 91.76%
0:02:23.464899s elapsed

Epoch: 2 / 100:
train: Loss: 0.1466 Accuracy: 415751 / 437991 = 94.92%
dev:   Loss: 0.2242 Accuracy: 19139 / 20454 = 93.57%
0:02:26.779544s elapsed

Epoch: 3 / 100:
train: Loss: 0.1153 Accuracy: 420254 / 437991 = 95.95%
dev:   Loss: 0.2097 Accuracy: 19216 / 20454 = 93.95%
0:02:31.800230s elapsed

Epoch: 4 / 100:
train: Loss: 0.0936 Accuracy: 423484 / 437991 = 96.69%
dev:   Loss: 0.1990 Accuracy: 19323 / 20454 = 94.47%
0:02:46.300920s elapsed

Epoch: 5 / 100:
train: Loss: 0.0797 Accuracy: 425491 / 437991 = 97.15%
dev:   Loss: 0.2017 Accuracy: 19337 / 20454 = 94.54%
0:02:33.001199s elapsed

Epoch: 6 / 100:
train: Loss: 0.0690 Accuracy: 427192 / 437991 = 97.53%
dev:   Loss: 0.1996 Accuracy: 19375 / 20454 = 94.72%
0:02:18.647527s elapsed

Epoch: 7 / 100:
train: Loss: 0.0607 Accuracy: 428413 / 437991 = 97.81%
dev:   Loss: 0.1993 Accuracy: 19391 / 20454 = 94.80%
0:02:31.499669s elapsed

Epoch: 8 / 100:
train: Loss: 0.0541 Accuracy: 429206 / 437991 = 97.99%
dev:   Loss: 0.1987 Accuracy: 19373 / 20454 = 94.71%
0:02:27.535453s elapsed

Epoch: 9 / 100:
train: Loss: 0.0497 Accuracy: 430022 / 437991 = 98.18%
dev:   Loss: 0.2009 Accuracy: 19388 / 20454 = 94.79%
0:02:23.205669s elapsed

Epoch: 10 / 100:
train: Loss: 0.0436 Accuracy: 430856 / 437991 = 98.37%
dev:   Loss: 0.2056 Accuracy: 19406 / 20454 = 94.88%
0:02:22.506830s elapsed

Epoch: 11 / 100:
train: Loss: 0.0389 Accuracy: 431786 / 437991 = 98.58%
dev:   Loss: 0.2061 Accuracy: 19424 / 20454 = 94.96%
0:02:21.682179s elapsed

Epoch: 12 / 100:
train: Loss: 0.0347 Accuracy: 432441 / 437991 = 98.73%
dev:   Loss: 0.2135 Accuracy: 19424 / 20454 = 94.96%
0:02:28.668769s elapsed

Epoch: 13 / 100:
train: Loss: 0.0322 Accuracy: 432887 / 437991 = 98.83%
dev:   Loss: 0.2149 Accuracy: 19399 / 20454 = 94.84%
0:02:27.967461s elapsed

Epoch: 14 / 100:
train: Loss: 0.0283 Accuracy: 433589 / 437991 = 98.99%
dev:   Loss: 0.2150 Accuracy: 19415 / 20454 = 94.92%
0:02:18.937915s elapsed

Epoch: 15 / 100:
train: Loss: 0.0257 Accuracy: 434011 / 437991 = 99.09%
dev:   Loss: 0.2277 Accuracy: 19373 / 20454 = 94.71%
0:02:22.854571s elapsed

Epoch: 16 / 100:
train: Loss: 0.0231 Accuracy: 434466 / 437991 = 99.20%
dev:   Loss: 0.2320 Accuracy: 19386 / 20454 = 94.78%
0:02:12.178949s elapsed

Epoch: 17 / 100:
train: Loss: 0.0208 Accuracy: 434871 / 437991 = 99.29%
dev:   Loss: 0.2416 Accuracy: 19397 / 20454 = 94.83%
0:01:59.973552s elapsed

Epoch: 18 / 100:
train: Loss: 0.0192 Accuracy: 435007 / 437991 = 99.32%
dev:   Loss: 0.2489 Accuracy: 19335 / 20454 = 94.53%
0:02:02.267292s elapsed

Epoch: 19 / 100:
train: Loss: 0.0167 Accuracy: 435561 / 437991 = 99.45%
dev:   Loss: 0.2425 Accuracy: 19366 / 20454 = 94.68%
0:01:53.493395s elapsed

Epoch: 20 / 100:
train: Loss: 0.0148 Accuracy: 435867 / 437991 = 99.52%
dev:   Loss: 0.2433 Accuracy: 19375 / 20454 = 94.72%
0:01:59.670905s elapsed

Epoch: 21 / 100:
train: Loss: 0.0136 Accuracy: 436078 / 437991 = 99.56%
dev:   Loss: 0.2579 Accuracy: 19359 / 20454 = 94.65%
0:01:52.445003s elapsed

Epoch: 22 / 100:
train: Loss: 0.0126 Accuracy: 436266 / 437991 = 99.61%
dev:   Loss: 0.2586 Accuracy: 19364 / 20454 = 94.67%
0:01:52.708215s elapsed

max accuracy of dev is 94.96% at epoch 11
mean time of each epoch is 0:02:18.072279s

test:  Loss: 0.1658 Accuracy: 47531 / 50319 = 94.46%
0:50:39.194189s elapsed

