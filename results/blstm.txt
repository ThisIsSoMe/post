Set max num of threads to 4
Preprocess the data
Corpus(
  num of sentences: 16091
  num of words: 54303
  num of tags: 32
  num of chars: 7477
)

Load the dataset
  size of trainset: 16091
  size of devset: 803
  size of testset: 1910

Create Neural Network
  vocdim: 54303
  embdim: 100
  hiddim: 300
  outdim: 32
  lossfn: cross_entropy

LSTM(
  (embed): Embedding(54303, 100)
  (lstm): LSTM(100, 150, batch_first=True, bidirectional=True)
  (out): Linear(in_features=300, out_features=32, bias=True)
  (drop): Dropout(p=0.5)
)

Use Adam optimizer to train the network
  epochs: 100
  batch_size: 25
  interval: 10
  eta: 0.001

Epoch: 1 / 100:
train: Loss: 0.1706 Accuracy: 412328 / 437991 = 94.14%
dev:   Loss: 0.2480 Accuracy: 18966 / 20454 = 92.73%
0:01:40.972065s elapsed

Epoch: 2 / 100:
train: Loss: 0.1042 Accuracy: 422561 / 437991 = 96.48%
dev:   Loss: 0.2103 Accuracy: 19230 / 20454 = 94.02%
0:01:48.460003s elapsed

Epoch: 3 / 100:
train: Loss: 0.0744 Accuracy: 426799 / 437991 = 97.44%
dev:   Loss: 0.2022 Accuracy: 19275 / 20454 = 94.24%
0:01:47.891300s elapsed

Epoch: 4 / 100:
train: Loss: 0.0567 Accuracy: 429497 / 437991 = 98.06%
dev:   Loss: 0.2015 Accuracy: 19290 / 20454 = 94.31%
0:02:24.290855s elapsed

Epoch: 5 / 100:
train: Loss: 0.0445 Accuracy: 431398 / 437991 = 98.49%
dev:   Loss: 0.2183 Accuracy: 19266 / 20454 = 94.19%
0:01:54.277475s elapsed

Epoch: 6 / 100:
train: Loss: 0.0352 Accuracy: 432767 / 437991 = 98.81%
dev:   Loss: 0.2285 Accuracy: 19243 / 20454 = 94.08%
0:01:56.588984s elapsed

Epoch: 7 / 100:
train: Loss: 0.0279 Accuracy: 433880 / 437991 = 99.06%
dev:   Loss: 0.2436 Accuracy: 19222 / 20454 = 93.98%
0:02:11.778941s elapsed

Epoch: 8 / 100:
train: Loss: 0.0211 Accuracy: 435052 / 437991 = 99.33%
dev:   Loss: 0.2585 Accuracy: 19219 / 20454 = 93.96%
0:02:08.769010s elapsed

Epoch: 9 / 100:
train: Loss: 0.0172 Accuracy: 435608 / 437991 = 99.46%
dev:   Loss: 0.2626 Accuracy: 19202 / 20454 = 93.88%
0:02:02.768580s elapsed

Epoch: 10 / 100:
train: Loss: 0.0131 Accuracy: 436261 / 437991 = 99.61%
dev:   Loss: 0.3016 Accuracy: 19189 / 20454 = 93.82%
0:02:07.123631s elapsed

Epoch: 11 / 100:
train: Loss: 0.0103 Accuracy: 436740 / 437991 = 99.71%
dev:   Loss: 0.3174 Accuracy: 19181 / 20454 = 93.78%
0:02:06.953742s elapsed

Epoch: 12 / 100:
train: Loss: 0.0079 Accuracy: 437063 / 437991 = 99.79%
dev:   Loss: 0.3376 Accuracy: 19198 / 20454 = 93.86%
0:02:02.925485s elapsed

Epoch: 13 / 100:
train: Loss: 0.0063 Accuracy: 437239 / 437991 = 99.83%
dev:   Loss: 0.3579 Accuracy: 19168 / 20454 = 93.71%
0:02:06.968194s elapsed

Epoch: 14 / 100:
train: Loss: 0.0047 Accuracy: 437495 / 437991 = 99.89%
dev:   Loss: 0.3559 Accuracy: 19168 / 20454 = 93.71%
0:02:02.681253s elapsed

Epoch: 15 / 100:
train: Loss: 0.0040 Accuracy: 437541 / 437991 = 99.90%
dev:   Loss: 0.3722 Accuracy: 19171 / 20454 = 93.73%
0:02:09.085714s elapsed

max accuracy of dev is 94.31% at epoch 4
mean time of each epoch is 0:02:02.102349s

test:  Loss: 0.1871 Accuracy: 47199 / 50319 = 93.80%
0:30:32.578261s elapsed

