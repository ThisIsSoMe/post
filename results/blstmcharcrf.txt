Set max num of threads to 4
Preprocess the data
Corpus(
  num of sentences: 16091
  num of words: 54303
  num of tags: 32
  num of chars: 7477
)

Load the dataset
  size of trainset: 16091
  size of devset: 803
  size of testset: 1910

Create Neural Network
  vocdim: 54303
  chrdim: 7477
  embdim: 100
  char_hiddim: 200
  hiddim: 300
  outdim: 32

LSTM_CHAR(
  (embed): Embedding(54303, 100)
  (clstm): CharLSTM(
    (embed): Embedding(7477, 100)
    (lstm): LSTM(100, 100, batch_first=True, bidirectional=True)
  )
  (wlstm): LSTM(300, 150, batch_first=True, bidirectional=True)
  (out): Linear(in_features=300, out_features=32, bias=True)
  (crf): CRF()
  (drop): Dropout(p=0.5)
  (lossfn): CrossEntropyLoss()
)

Use Adam optimizer to train the network
  epochs: 100
  batch_size: 50
  interval: 10
  eta: 0.001

Epoch: 1 / 100:
train: Loss: 5.8238 Accuracy: 405957 / 437991 = 92.69%
dev:   Loss: 5.6102 Accuracy: 18854 / 20454 = 92.18%
0:03:36.479371s elapsed

Epoch: 2 / 100:
train: Loss: 4.0399 Accuracy: 415604 / 437991 = 94.89%
dev:   Loss: 4.3351 Accuracy: 19201 / 20454 = 93.87%
0:03:42.357357s elapsed

Epoch: 3 / 100:
train: Loss: 3.2784 Accuracy: 419684 / 437991 = 95.82%
dev:   Loss: 3.8975 Accuracy: 19336 / 20454 = 94.53%
0:03:34.097876s elapsed

Epoch: 4 / 100:
train: Loss: 2.8185 Accuracy: 422053 / 437991 = 96.36%
dev:   Loss: 3.7157 Accuracy: 19388 / 20454 = 94.79%
0:03:34.757601s elapsed

Epoch: 5 / 100:
train: Loss: 2.4131 Accuracy: 424439 / 437991 = 96.91%
dev:   Loss: 3.4340 Accuracy: 19488 / 20454 = 95.28%
0:03:37.839422s elapsed

Epoch: 6 / 100:
train: Loss: 2.1310 Accuracy: 426123 / 437991 = 97.29%
dev:   Loss: 3.4458 Accuracy: 19498 / 20454 = 95.33%
0:03:38.165378s elapsed

Epoch: 7 / 100:
train: Loss: 1.9185 Accuracy: 427234 / 437991 = 97.54%
dev:   Loss: 3.4157 Accuracy: 19525 / 20454 = 95.46%
0:03:37.707379s elapsed

Epoch: 8 / 100:
train: Loss: 1.7496 Accuracy: 428261 / 437991 = 97.78%
dev:   Loss: 3.4604 Accuracy: 19515 / 20454 = 95.41%
0:03:36.707120s elapsed

Epoch: 9 / 100:
train: Loss: 1.5712 Accuracy: 429215 / 437991 = 98.00%
dev:   Loss: 3.3764 Accuracy: 19566 / 20454 = 95.66%
0:03:40.333141s elapsed

Epoch: 10 / 100:
train: Loss: 1.4239 Accuracy: 430112 / 437991 = 98.20%
dev:   Loss: 3.3850 Accuracy: 19543 / 20454 = 95.55%
0:03:38.600365s elapsed

Epoch: 11 / 100:
train: Loss: 1.3117 Accuracy: 430689 / 437991 = 98.33%
dev:   Loss: 3.4808 Accuracy: 19537 / 20454 = 95.52%
0:03:32.727092s elapsed

Epoch: 12 / 100:
train: Loss: 1.1860 Accuracy: 431391 / 437991 = 98.49%
dev:   Loss: 3.4966 Accuracy: 19529 / 20454 = 95.48%
0:03:42.562715s elapsed

Epoch: 13 / 100:
train: Loss: 1.0764 Accuracy: 432131 / 437991 = 98.66%
dev:   Loss: 3.5418 Accuracy: 19554 / 20454 = 95.60%
0:03:46.053602s elapsed

Epoch: 14 / 100:
train: Loss: 0.9761 Accuracy: 432700 / 437991 = 98.79%
dev:   Loss: 3.5598 Accuracy: 19574 / 20454 = 95.70%
0:03:31.293883s elapsed

Epoch: 15 / 100:
train: Loss: 0.8978 Accuracy: 433137 / 437991 = 98.89%
dev:   Loss: 3.6118 Accuracy: 19551 / 20454 = 95.59%
0:03:38.493840s elapsed

Epoch: 16 / 100:
train: Loss: 0.8229 Accuracy: 433527 / 437991 = 98.98%
dev:   Loss: 3.6426 Accuracy: 19541 / 20454 = 95.54%
0:03:43.356052s elapsed

Epoch: 17 / 100:
train: Loss: 0.7559 Accuracy: 433947 / 437991 = 99.08%
dev:   Loss: 3.6275 Accuracy: 19558 / 20454 = 95.62%
0:03:37.306725s elapsed

Epoch: 18 / 100:
train: Loss: 0.6955 Accuracy: 434269 / 437991 = 99.15%
dev:   Loss: 3.7838 Accuracy: 19531 / 20454 = 95.49%
0:03:34.674740s elapsed

Epoch: 19 / 100:
train: Loss: 0.6485 Accuracy: 434517 / 437991 = 99.21%
dev:   Loss: 3.7953 Accuracy: 19548 / 20454 = 95.57%
0:03:34.652822s elapsed

Epoch: 20 / 100:
train: Loss: 0.5843 Accuracy: 434854 / 437991 = 99.28%
dev:   Loss: 3.8089 Accuracy: 19578 / 20454 = 95.72%
0:03:33.740918s elapsed

Epoch: 21 / 100:
train: Loss: 0.5267 Accuracy: 435233 / 437991 = 99.37%
dev:   Loss: 3.9286 Accuracy: 19561 / 20454 = 95.63%
0:03:13.486069s elapsed

Epoch: 22 / 100:
train: Loss: 0.4952 Accuracy: 435412 / 437991 = 99.41%
dev:   Loss: 3.9986 Accuracy: 19542 / 20454 = 95.54%
0:03:10.457123s elapsed

Epoch: 23 / 100:
train: Loss: 0.4549 Accuracy: 435646 / 437991 = 99.46%
dev:   Loss: 4.1020 Accuracy: 19533 / 20454 = 95.50%
0:03:11.069140s elapsed

Epoch: 24 / 100:
train: Loss: 0.4140 Accuracy: 435907 / 437991 = 99.52%
dev:   Loss: 4.1291 Accuracy: 19529 / 20454 = 95.48%
0:03:10.072277s elapsed

Epoch: 25 / 100:
train: Loss: 0.3771 Accuracy: 436077 / 437991 = 99.56%
dev:   Loss: 4.2925 Accuracy: 19500 / 20454 = 95.34%
0:03:28.090726s elapsed

Epoch: 26 / 100:
train: Loss: 0.3638 Accuracy: 436185 / 437991 = 99.59%
dev:   Loss: 4.3473 Accuracy: 19502 / 20454 = 95.35%
0:03:35.741165s elapsed

Epoch: 27 / 100:
train: Loss: 0.3274 Accuracy: 436391 / 437991 = 99.63%
dev:   Loss: 4.3046 Accuracy: 19518 / 20454 = 95.42%
0:03:28.830403s elapsed

Epoch: 28 / 100:
train: Loss: 0.2988 Accuracy: 436497 / 437991 = 99.66%
dev:   Loss: 4.4705 Accuracy: 19509 / 20454 = 95.38%
0:03:32.408320s elapsed

Epoch: 29 / 100:
train: Loss: 0.2741 Accuracy: 436637 / 437991 = 99.69%
dev:   Loss: 4.6101 Accuracy: 19515 / 20454 = 95.41%
0:03:31.710737s elapsed

Epoch: 30 / 100:
train: Loss: 0.2489 Accuracy: 436801 / 437991 = 99.73%
dev:   Loss: 4.6495 Accuracy: 19491 / 20454 = 95.29%
0:03:33.259445s elapsed

Epoch: 31 / 100:
train: Loss: 0.2318 Accuracy: 436867 / 437991 = 99.74%
dev:   Loss: 4.6964 Accuracy: 19503 / 20454 = 95.35%
0:03:34.476048s elapsed

max accuracy of dev is 95.72% at epoch 20
mean time of each epoch is 0:03:32.951898s

test:  Loss: 3.9697 Accuracy: 48001 / 50319 = 95.39%
1:50:05.142425s elapsed

