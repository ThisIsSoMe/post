Set max num of threads to 4
Preprocess the data
Corpus(
  num of sentences: 16091
  num of words: 54303
  num of tags: 32
  num of chars: 7477
)

Load the dataset
  size of trainset: 16091
  size of devset: 803
  size of testset: 1910

Create Neural Network
  vocdim: 54303
  chrdim: 7477
  embdim: 100
  char_hiddim: 200
  hiddim: 300
  outdim: 32

LSTM_CHAR(
  (embed): Embedding(54303, 100)
  (clstm): CharLSTM(
    (embed): Embedding(7477, 100)
    (lstm): LSTM(100, 100, batch_first=True, bidirectional=True)
  )
  (wlstm): LSTM(300, 150, batch_first=True, bidirectional=True)
  (out): Linear(in_features=300, out_features=32, bias=True)
  (crf): CRF()
  (drop): Dropout(p=0.5)
)

Use Adam optimizer to train the network
  epochs: 100
  batch_size: 50
  interval: 10
  eta: 0.001

Epoch: 1 / 100:
train: Loss: 6.0219 Accuracy: 405870 / 437991 = 92.67%
dev:   Loss: 5.9504 Accuracy: 18860 / 20454 = 92.21%
0:03:46.189183s elapsed

Epoch: 2 / 100:
train: Loss: 4.2245 Accuracy: 414335 / 437991 = 94.60%
dev:   Loss: 4.7819 Accuracy: 19132 / 20454 = 93.54%
0:03:32.928405s elapsed

Epoch: 3 / 100:
train: Loss: 3.3865 Accuracy: 419079 / 437991 = 95.68%
dev:   Loss: 4.2838 Accuracy: 19287 / 20454 = 94.29%
0:03:31.118535s elapsed

Epoch: 4 / 100:
train: Loss: 2.8989 Accuracy: 421608 / 437991 = 96.26%
dev:   Loss: 4.1803 Accuracy: 19340 / 20454 = 94.55%
0:03:32.195997s elapsed

Epoch: 5 / 100:
train: Loss: 2.5329 Accuracy: 423726 / 437991 = 96.74%
dev:   Loss: 3.9760 Accuracy: 19425 / 20454 = 94.97%
0:03:40.798121s elapsed

Epoch: 6 / 100:
train: Loss: 2.3251 Accuracy: 425053 / 437991 = 97.05%
dev:   Loss: 4.0541 Accuracy: 19432 / 20454 = 95.00%
0:03:32.406478s elapsed

Epoch: 7 / 100:
train: Loss: 2.0251 Accuracy: 426751 / 437991 = 97.43%
dev:   Loss: 3.8575 Accuracy: 19482 / 20454 = 95.25%
0:03:37.737208s elapsed

Epoch: 8 / 100:
train: Loss: 1.8452 Accuracy: 427621 / 437991 = 97.63%
dev:   Loss: 4.0572 Accuracy: 19473 / 20454 = 95.20%
0:03:38.621355s elapsed

Epoch: 9 / 100:
train: Loss: 1.6574 Accuracy: 428842 / 437991 = 97.91%
dev:   Loss: 3.8891 Accuracy: 19506 / 20454 = 95.37%
0:03:32.088670s elapsed

Epoch: 10 / 100:
train: Loss: 1.5405 Accuracy: 429430 / 437991 = 98.05%
dev:   Loss: 4.0294 Accuracy: 19528 / 20454 = 95.47%
0:03:35.019973s elapsed

Epoch: 11 / 100:
train: Loss: 1.4200 Accuracy: 430257 / 437991 = 98.23%
dev:   Loss: 4.0434 Accuracy: 19525 / 20454 = 95.46%
0:03:38.156996s elapsed

Epoch: 12 / 100:
train: Loss: 1.2896 Accuracy: 430831 / 437991 = 98.37%
dev:   Loss: 4.0687 Accuracy: 19537 / 20454 = 95.52%
0:03:38.432012s elapsed

Epoch: 13 / 100:
train: Loss: 1.1631 Accuracy: 431613 / 437991 = 98.54%
dev:   Loss: 3.9683 Accuracy: 19552 / 20454 = 95.59%
0:03:38.858312s elapsed

Epoch: 14 / 100:
train: Loss: 1.1057 Accuracy: 431977 / 437991 = 98.63%
dev:   Loss: 4.0715 Accuracy: 19524 / 20454 = 95.45%
0:03:37.553926s elapsed

Epoch: 15 / 100:
train: Loss: 0.9980 Accuracy: 432571 / 437991 = 98.76%
dev:   Loss: 4.1372 Accuracy: 19512 / 20454 = 95.39%
0:03:33.762284s elapsed

Epoch: 16 / 100:
train: Loss: 0.8881 Accuracy: 433300 / 437991 = 98.93%
dev:   Loss: 4.2144 Accuracy: 19547 / 20454 = 95.57%
0:03:39.663806s elapsed

Epoch: 17 / 100:
train: Loss: 0.8268 Accuracy: 433593 / 437991 = 99.00%
dev:   Loss: 4.2151 Accuracy: 19525 / 20454 = 95.46%
0:03:45.110389s elapsed

Epoch: 18 / 100:
train: Loss: 0.7573 Accuracy: 433966 / 437991 = 99.08%
dev:   Loss: 4.1960 Accuracy: 19537 / 20454 = 95.52%
0:03:37.386591s elapsed

Epoch: 19 / 100:
train: Loss: 0.7127 Accuracy: 434197 / 437991 = 99.13%
dev:   Loss: 4.2812 Accuracy: 19537 / 20454 = 95.52%
0:03:35.137191s elapsed

Epoch: 20 / 100:
train: Loss: 0.6402 Accuracy: 434717 / 437991 = 99.25%
dev:   Loss: 4.4051 Accuracy: 19517 / 20454 = 95.42%
0:03:37.514868s elapsed

Epoch: 21 / 100:
train: Loss: 0.5751 Accuracy: 435042 / 437991 = 99.33%
dev:   Loss: 4.3532 Accuracy: 19564 / 20454 = 95.65%
0:03:33.581292s elapsed

Epoch: 22 / 100:
train: Loss: 0.5314 Accuracy: 435279 / 437991 = 99.38%
dev:   Loss: 4.4932 Accuracy: 19505 / 20454 = 95.36%
0:03:33.834621s elapsed

Epoch: 23 / 100:
train: Loss: 0.4905 Accuracy: 435517 / 437991 = 99.44%
dev:   Loss: 4.5452 Accuracy: 19531 / 20454 = 95.49%
0:03:28.792977s elapsed

Epoch: 24 / 100:
train: Loss: 0.4625 Accuracy: 435606 / 437991 = 99.46%
dev:   Loss: 4.6953 Accuracy: 19519 / 20454 = 95.43%
0:03:29.851288s elapsed

Epoch: 25 / 100:
train: Loss: 0.4135 Accuracy: 435873 / 437991 = 99.52%
dev:   Loss: 4.8231 Accuracy: 19515 / 20454 = 95.41%
0:03:24.794924s elapsed

Epoch: 26 / 100:
train: Loss: 0.3949 Accuracy: 435992 / 437991 = 99.54%
dev:   Loss: 4.8354 Accuracy: 19509 / 20454 = 95.38%
0:03:29.181503s elapsed

Epoch: 27 / 100:
train: Loss: 0.3604 Accuracy: 436225 / 437991 = 99.60%
dev:   Loss: 4.8822 Accuracy: 19516 / 20454 = 95.41%
0:03:34.224560s elapsed

Epoch: 28 / 100:
train: Loss: 0.3232 Accuracy: 436422 / 437991 = 99.64%
dev:   Loss: 4.9838 Accuracy: 19501 / 20454 = 95.34%
0:03:41.682017s elapsed

Epoch: 29 / 100:
train: Loss: 0.2977 Accuracy: 436607 / 437991 = 99.68%
dev:   Loss: 4.9282 Accuracy: 19521 / 20454 = 95.44%
0:03:39.338186s elapsed

Epoch: 30 / 100:
train: Loss: 0.2817 Accuracy: 436671 / 437991 = 99.70%
dev:   Loss: 5.0821 Accuracy: 19493 / 20454 = 95.30%
0:03:41.118899s elapsed

Epoch: 31 / 100:
train: Loss: 0.2511 Accuracy: 436811 / 437991 = 99.73%
dev:   Loss: 5.2418 Accuracy: 19504 / 20454 = 95.36%
0:03:47.450378s elapsed

Epoch: 32 / 100:
train: Loss: 0.2350 Accuracy: 436898 / 437991 = 99.75%
dev:   Loss: 5.2986 Accuracy: 19524 / 20454 = 95.45%
0:03:35.771619s elapsed

max accuracy of dev is 95.65% at epoch 21
mean time of each epoch is 0:03:36.259455s

test:  Loss: 3.8848 Accuracy: 48036 / 50319 = 95.46%
1:55:26.347477s elapsed

